# ğŸ›’ Retail Sales ETL Pipeline with PySpark

This project simulates a real-world retail sales data pipeline using PySpark and Delta Lake on Databricks.

## âœ… Features
- Ingest CSV data from Azure Data Lake
- Clean and transform using PySpark DataFrames
- Load into Delta Lake format
- Calculate KPIs like daily revenue, top products, and store performance

## ğŸ§° Tech Stack
- PySpark
- Databricks
- Delta Lake
- Azure Data Lake Storage (ADLS Gen2)
- CSV

## ğŸ“ FolderÂ Structure
Retail-Sales-ETL-Pipeline/
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
## ğŸ“Š KPIs Generated
- ğŸ§¾ Daily Revenue
- ğŸª Store-wise Sales Performance
- ğŸ” Top 5 Products by Revenue

## ğŸ“¸ Pipeline Flow
1. Raw CSV Data â†’ Azure Data Lake
2. Databricks PySpark Ingestion
3. Data Cleaning & Transformation
4. Delta Lake Write-back
5. KPI Computation

## ğŸ‘¨â€ğŸ’» Author
*Sabari Gireesh Kamurthy*  
[LinkedIn](https://www.linkedin.com/in/sabarigireesh-kamurthy)