# 🛒 Retail Sales ETL Pipeline with PySpark

This project simulates a real-world retail sales data pipeline using PySpark and Delta Lake on Databricks.

## ✅ Features
- Ingest CSV data from Azure Data Lake
- Clean and transform using PySpark DataFrames
- Load into Delta Lake format
- Calculate KPIs like daily revenue, top products, and store performance

## 🧰 Tech Stack
- PySpark
- Databricks
- Delta Lake
- Azure Data Lake Storage (ADLS Gen2)
- CSV

## 📁 Folder Structure
Retail-Sales-ETL-Pipeline/
├── data/
├── notebooks/
├── README.md
└── requirements.txt
## 📊 KPIs Generated
- 🧾 Daily Revenue
- 🏪 Store-wise Sales Performance
- 🔝 Top 5 Products by Revenue

## 📸 Pipeline Flow
1. Raw CSV Data → Azure Data Lake
2. Databricks PySpark Ingestion
3. Data Cleaning & Transformation
4. Delta Lake Write-back
5. KPI Computation

## 👨‍💻 Author
*Sabari Gireesh Kamurthy*  
[LinkedIn](https://www.linkedin.com/in/sabarigireesh-kamurthy)